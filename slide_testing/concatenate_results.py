"""
In our pipeline, we do the following:
    1. Use our model to generate predictions on unlabeled images (generate_predictions.py)
    2. Use our predictions to generate subsection display images (generate_display_results.py)
And this file is #3,

In generate_display_results.py, before this, we convert our predictions.h5 file into a bunch of overlay images,
    with the predictions overlaid on top of the original grayscale images. 
Unfortunately, these grayscale images are massive, so this is done by generating overlay subsection images and scaling them down (resizing down),
    instead of one big overlay image on top of the entire grayscale image.
This file takes those subsection images generated by generate_display_results.py,
    and combines them into entire image results.

It works with both static divide factors, and dynamic, 
    i.e. some images aren't divided and have 1 final subsection, while some may be
        divided a bunch and have 64 total subsections, and so on.

So you can run it after generating the display result images and it should Just Work:tm:

-Blake Edwards / Dark Element
"""

import sys, os, pickle, re
import numpy as np
import cv2

def clear_dir(dir):
    """
    Arguments:
        dir: A string directory to clear of all files and sub-directories.

    Returns:
        Clears/Deletes all files and sub-directories in the given dir, using python's os methods
        Has no return value.
    """
    for fname in os.listdir(dir):
        fpath = os.path.join(dir, fname)
        try: 
            if os.path.isfile(fpath):
                os.unlink(fpath)
        except:
            pass

def recursive_get_paths(img_dir):
    """
    Arguments:
        img_dir : directory to recursively traverse. Should be a string.

    Returns:
        A list of tuples, where each tuple is of the form
            (path and filename str, filename str), e.g.
            ("/home/darkelement/test.txt", "test.txt")
    """
    paths = []
    for (path, dirs, fnames) in os.walk(img_dir):
        for fname in fnames:
            paths.append((os.path.join(path, fname), fname))
    return paths

def get_concatenated_row(samples):
    """
    Concatenate each sample in samples horizontally, along axis 1.
    Return the resulting array.
    """
    return np.concatenate([sample for sample in samples], axis=1)

def get_concatenated_col(samples):
    """
    Concatenate each sample in samples vertically, along axis 0.
    Return the resulting array.
    """
    return np.concatenate([sample for sample in samples], axis=0)

def get_img_ns(img_fnames):
    """
    Arguments:
        img_fnames: A sorted list of filenames, where each image is of the form i_r_c.jpg
            Where 
                i = image index, 
                r = row index,
                c = col index
            So that we can look at the first index for this function.
    Returns:
        A list of integers, where:
            the integer represents the number of subsections in the image represented 
            by that integer's index in the list:
                e.g. for [4, 64, 36], 
                    Image 0: 4 subsections, 
                    Image 1: 64 subsections, 
                    Image 2: 36 subsections
        We go through img_fnames and get the number of image files that have the same image index, 
            returning a list where the indices match up to show the number
    """
    img_ns = []
    for fname in img_fnames:
        """
        Get image index
        """
        img_i = int(fname.split("_")[0])

        """
        Update number for this image index
        """
        if len(img_ns) <= img_i:
            """
            If we don't have it yet, add 1 because this is the first and therefore the count is now 1
            """
            img_ns.append(1)
        else:
            """
            If we do have it, increment the count for this image by 1
            """
            img_ns[img_i] += 1

    return img_ns

def concatenate_results(results_dir, concatenated_results_dir, classification_metadata_dir=None):
    """
    Arguments:
        results_dir:
            Our main directory of subsection display results, which we can iterate through to obtain our subsection images which we will concatenate.
            Images here should be formatted like i_r_c.jpg,
            Where 
                i = image index, 
                r = row index,
                c = col index
            So that we can easily combine them in the right way using this file.

        concatenated_results_dir:
            Our destination directory, where the concatenated result images will be stored.

        classification_metadata_dir:
            A string filepath of the .pkl file where the model's classification strings and color key for each classification will be stored.
            Note: Leave this as None to not add a classification key to our concatenated images.

    Returns:
        Goes through each image in results_dir, and concatenates them together to form an entire image from constituent parts,
            then adds a color key to these images in the top left if given classification_metadata_dir,
            then stores these images according to their image number in concatenated_results_dir.
    """

    """
    Remove any existing files in our resulting directory
    """
    clear_dir(concatenated_results_dir)
    
    """
    Get all our paths and fill list with only the paths
    """
    overlay_sub_img_path_infos = recursive_get_paths(results_dir)
    overlay_sub_img_paths = [path for path, fname in overlay_sub_img_path_infos]

    """
    Then, we sort with priority order Image #, Row #, Col #.
    """
    convert = lambda text: int(text) if text.isdigit() else text.lower() 
    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)] 
    overlay_sub_img_paths = sorted(overlay_sub_img_paths, key=alphanum_key)

    """
    Split on os separation of file names in directory paths
    """
    overlay_sub_imgs = [overlay_sub_img_path.split(os.sep)[-1] for overlay_sub_img_path in overlay_sub_img_paths]

    """
    Get the number of subsections for each image
    """
    img_ns = get_img_ns(overlay_sub_imgs)
        
    """
    Prepare our image path storage list, which we will use for getting the full paths of each of our subsection images. 
    """
    img_subs = [[] for img_i in img_ns]

    for overlay_sub_img in overlay_sub_imgs:
        """
        Loop through our images, and parse out the image # for reference, then append the properly formatted filepath
        """
        img_i = int(overlay_sub_img.split("_")[0])

        """
        Append our sub img paths to a vector for each image so we can form the full matrix later
        """
        img_subs[img_i].append(os.path.join(results_dir, overlay_sub_img))

    for img_i, img in enumerate(img_subs):
        """
        Print progress
        """
        sys.stdout.write("\rConcatenating Image #%i" % img_i)
        sys.stdout.flush()

        """
        We calculate our img_n, row_n, and col_n using our info for each img stored in img_ns list
            We assume our images are divided evenly into squares, e.g. 16 = 4x4, 64 = 8x8, etc.
            This will always be true if we use the programs in our pipeline.
        """
        img_n = img_ns[img_i]
        row_n = int(np.sqrt(img_n))
        col_n = row_n

        """
        Each img is a vector of the subsections, ordered left to right, top to bottom.
            So, we can convert it to a np array and reshape!
        """
        img = np.array(img).reshape((row_n, col_n))

        """
        Make a vector of lists, where each list is a row in the image.
            This way, we can go through and concatenate the row together,
            then append them, without knowing how big the image is.
        """
        """
        Create vector for our row images, to be stored in a concatenated column at the end
        """
        result_rows = [[] for row_i in range(row_n)]
        for row_i, row in enumerate(img):
            """
            Create vector for our column images, to be stored in a concatenated row at the end
            """
            result_cols = [[] for col_i in range(col_n)]
            for col_i, col in enumerate(row):
                """
                Read the image from our path and place in our result_cols
                """
                result_cols[col_i] = cv2.imread(img[row_i][col_i])
            """
            Get a concatenated row by combining our columns horizontally
            """
            result_cols = get_concatenated_row(result_cols)
            result_rows[row_i] = result_cols
        """
        Get a full image by concatenating all our rows together vertically
        """
        result_img = get_concatenated_col(result_rows)

        if classification_metadata_dir:
            """
            If we have a classification_metadata_dir (if classification_metadata_dir != None),
                Load our classifications and colors
            """
            f = open(classification_metadata_dir, 'r')
            classification_metadata = pickle.load(f)
            classifications = classification_metadata[0]
            colors = classification_metadata[1]

            """
            With these, we loop through them simultaneously and also increment the position of our color key text in the top left corner of our image
                and place our classification text at this incremented position, with the color specified by our color list.
            This way, we have 0, 1, 2, 3, in order from top down, and each key is colored accordingly.
                Note: we do 80x + 50 so we get the pattern of 50, 130, 210, etc to start at 50 and increment by 80
            """
            for classification_i, classification in enumerate(classifications):
                cv2.putText(result_img, classifications[classification_i], (0, 80*classification_i + 50), cv2.FONT_HERSHEY_SIMPLEX, 2, colors[classification_i], 4)

        """
        Finally, write our result_img to properly formatted filename
        """
        cv2.imwrite("%s%s%i.jpg" % (concatenated_results_dir, os.sep, img_i), result_img)

    print ""#Flush print formatting
                
concatenate_results("results/", "concatenated_results/", classification_metadata_dir="classification_metadata.pkl")
