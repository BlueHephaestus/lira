"""
This is our script to post process predictions generated by our classifier on images, as well as any other data that needs post-processing.

Further documentation found in each function.

-Blake Edwards / Dark Element
"""
import sys
import numpy as np

def denoise_predictions(src, epochs):
    """
    Arguments:
        src: np array of shape (h, w, class_n), the source image.
        class_n: int number of classes / classifications we will find in our src img.
        epochs: int number of denoising iterations to put our src image through.
            Note: set this to 0 if you don't want denoising.

    Returns
        For each pixel in our src image, 
            get the nearest neighbor pixels,
            get the cost of each class at this location with our cost function,
            then place the class with the lowest cost at the mirrored location in our destination image.
        Then repeat this process `epochs` number of times
    """
    h, w, class_n = src.shape
    
    neighbor_weight = 0.8

    costs = np.zeros((class_n))
    """
    Just in case we don't want any denoising, in which case we return the src.
    """
    if epochs == 0:
        return src

    """
    Since this is interacting with a file which has its own progress indicator,
        we write some blank space to clear the screen of any previous text before writing any of our progress indicator
    """
    sys.stdout.write("\r                                       ")

    for epoch in range(epochs):
        """
        Each loop, reset our destination image, which will contain the new denoised image.
        """
        dst = np.zeros((h,w))
        sys.stdout.write("\rDenoising Image... %i%%"%(int(float(epoch)/epochs*100)))
        sys.stdout.flush()
        for i in range(h):
            for j in range(w):
                """
                Get indices of neighbors
                """
                neighbors=get_neighbors(i,j,h,w)
                
                """
                Get cost of each class for this pixel in our src img
                """
                for class_i in range(class_n):
                    costs[class_i] = cost(class_i, src[i,j], src, neighbors, neighbor_weight, class_n)

                """
                Assign dst pixel to class with lowest cost.
                """
                dst[i,j] = np.argmin(costs)
        """
        Set src equal to dst, so that we can run this again on the result of the previous loop,
            and continue denoising the image for `epochs` times.
        """
        src = dst
    return dst


def get_neighbors(i,j,h,w):
    """
    Arguments:
        i,j: indices in our image matrix of size h,w
        h,w: size/dims of our image matrix

    Returns:
        neighbors: A list containing the index pairs of each of the neighbors of (i,j).
            For example, if i=0 and j=0, this would return [(0,1), (1,0), (1,1)]
        
            We do this by getting all adjacent neighbors, vertically, diagonally, and horizontally.
            We handle our edge cases by getting all 8 of these neighbors, then looping backwards through the list
                and removing those that aren't inside the bounds of our image.
    """
    neighbors=[(i-1, j-1), (i-1, j), (i-1, j+1), (i, j-1), (i, j+1), (i+1, j-1), (i+1, j), (i+1, j+1)]
    for neighbor_i in range(len(neighbors)-1, -1, -1):#Iterate from len-1 to 0
        sample_i, sample_j = neighbors[neighbor_i]
        if sample_i < 0 or sample_i > h-1 or sample_j < 0 or sample_j > w-1:
            del neighbors[neighbor_i]
    return neighbors

def cost(dst_val, src_val, src, neighbors, neighbor_weight, class_n):
    """
    Arguments:
        dst_val: Possible/Candidate value for the destination pixel. 0 <= dst_val < class_n
        src_val: The value of the source pixel. 0 <= src_val < class_n
        src: np array of shape (h, w), the source image. Used for referencing our neighbor indices
        neighbors: Our neighbor indices of our src pixel. See get_neighbors.
        neighbor_weight: 
            How much importance to put on the neighbor values. 
            This could also be thought of as a smoothing factor.
            Should be between 0 and 1
        class_n: int number of classes / classifications. 

    Returns:
        The cost of placing dst_val as the source pixel's src_val, given src_val and neighbors of src_val.
        The lower the cost, the better a candidate value dst_val is. 
    """
    """
    The values of the neighbor indices of our src pixel. We get these as a vector to speed up the cost computation.
    """
    neighbor_vals = np.array([src[neighbor] for neighbor in neighbors])

    """
    Compute our cost function as follows:
        
        C = (a * (mean((d - N)**2)) + (1-a) * (mean((d-s)**2)))
        
    Where 
        a is our neighbor weight, 
        n is our number of classes (since the values are n-length vectors),
        d is our destination value,
        s is our src value,
        and N is our neighbor value matrix, of size neighbor_n x n

    This has been simplified to allow for cheaper computation, however its format originally was:
        
        C = a * (sum(f(d, N_i)) + (1-a) * f(d, s))
        f(d, x) = mean((d-x)**2)

    Which makes much more sense. the f(d, x) function was chosen to just be the Mean Squared Error, 
        which I expanded and changed the extra sum(f(d, N_i)) to just be mean((d-N)**2), 
        since numpy adds the squared differences in the same manner as if I just did both sums:
            mean(sum((d-N_i)**2)) = 1/n * sum((d-N)**2) = mean((d-N)**2
        So I went with the right most equation because it was more compact.

    As for the f(d, s) equation, this was already very simplified.

    So, to recap:
        f(d, x) gives a value between 0 and 1 because d and x are between 0 and 1 (otherwise I would have used the radial basis function probably),
            which is close to 1 for very different values, and close to 0 for very similar values 
            It is the mean squared error cost function.
        a, (1-a) were used so that whatever the percent importance assigned to neighbors was (you could also think of this as a 0-1 weight), 
            the remaining percent would be assigned to the original src value, and we'd still get a sane equation for any values for "a" between 0 and 1
            If you don't think of it as percentages, then just think of it as a way to make sure the equation works for any values 0-1,
                and make sure that if there is high weight on neighbors, there is low weight on source values, and vice versa..
    """
    return (neighbor_weight * (np.mean(np.square(dst_val - neighbor_vals))) + (1.-neighbor_weight) * (np.mean(np.square(dst_val-src_val))))
